{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "**Author:** Yimin\n",
    "\n",
    "Filling missing data\n",
    "\n",
    "- VehicleAge\n",
    "- VehOdo: check correlation with the VehicleAge\n",
    "- VNST: check inside ZIP codes how it behaves\n",
    "- Size: SUV are bad, sports shame on you\n",
    "- Make: check the best ones and the worst ones\n",
    "- Auction = 'ADESA'\n",
    "- WarrantyCost: continuous\n",
    "\n",
    "Not used for now:\n",
    "- (1) TopThreeAmericanName: group of Make\n",
    "- (2) PurchDate: check year and month\n",
    "- (2) PRIMEUNIT: if filled seems better\n",
    "- (2) AUCGUART: GREEN is good\n",
    "- (2) Model: try to combine maker and model (probability)\n",
    "- (2) Trim: Same as model\n",
    "- (2) WheelTypeID == WheelType\\* : 'Special' seems slightly bad\n",
    "- (2) VNZIP1 in combination with VNST\n",
    "- (3) SubModel: same as model\n",
    "- (-) Color: no relevance\n",
    "- (3) Transmission: Manual is slighly better\n",
    "- (-) Nationality: Country of the Make, check if 1-1\n",
    "- (?) MMR : continuous data\n",
    "- (?) BYRNO: goes hand in hand with Auction?\n",
    "- (?) VehBCost: continuous\n",
    "- (3) IsOnlineSale: online is sliiiiigghtly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model.logistic import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# JUST RUN ONCE\n",
    "X = pd.read_csv('../data_preprocessing/train_dummy.csv')\n",
    "y = pd.read_csv('../data_preprocessing/training.csv')['IsBadBuy']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train.to_csv('../xtrain.csv', index=False)\n",
    "X_test.to_csv('../xtest.csv', index=False)\n",
    "y_train.to_csv('../ytrain.csv', index=False, header=['IsBadBuy'])\n",
    "y_test.to_csv('../ytest.csv', index=False, header=['IsBadBuy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Make', 'Auction']\n",
    "def fill_missing(data, features):\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('training.csv')\n",
    "for feature in [ 'RefId','PurchDate','VehYear','Model', 'Trim', 'SubModel', 'WheelType', 'VNZIP1']:\n",
    "    data.drop([feature],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "feature_names = data.columns[0:].tolist()\n",
    "print('data_shape', data.shape)\n",
    "print('there are {} items'.format(data.shape[0]))\n",
    "print('there are {} charicteristics:{}'.format(len(feature_names),feature_names))\n",
    "\n",
    "## check the features which contain missing value\n",
    "\n",
    "missing_No = {}\n",
    "for feature in feature_names:\n",
    "    if len(data[feature][data[feature].isnull()]) > 0:\n",
    "        print(feature)\n",
    "        print(len(data[feature][data[feature].isnull()]))\n",
    "        missing_No[feature] = len(data[feature][data[feature].isnull()])\n",
    "print(missing_No)\n",
    "\n",
    "## filling the missing value for catrgory features.\n",
    "\n",
    "for feature in ['Color', 'Transmission', 'WheelTypeID', 'Nationality', 'Size', 'TopThreeAmericanName','PRIMEUNIT', 'AUCGUART']:\n",
    "    data[feature][data[feature].isnull()]='U0'\n",
    "\n",
    "## filling the missing value with average value for number features\n",
    "for key in missing_No:\n",
    "    if data[key].dtype !='object':\n",
    "        data[key][data[key].isnull()]=data[key].median()\n",
    "\n",
    "data = pd.get_dummies(data)\n",
    "#print(data.head())\n",
    "\n",
    "#separate training and test\n",
    "train = data.loc[0:72982]\n",
    "test = data.loc[72983:]\n",
    "\n",
    "\n",
    "#print(test)\n",
    "train.to_csv('train_dummy.csv',index=False,header=True)\n",
    "test.to_csv('test_dummy.csv',index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
